{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install \"gymnasium>=1.2.0\" \"imageio>=2.37.0\" \"lightning>=2.5.2\" \"matplotlib>=3.10.3\" \"minigrid>=3.0.0\" \"pyyaml>=6.0.2\" \"minigrid\" \"seaborn>=0.13.2\" \"tensorboard>=2.20.0\" \"torch>=2.7.1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T19:45:59.824148Z","iopub.execute_input":"2025-07-27T19:45:59.824447Z","iopub.status.idle":"2025-07-27T19:49:11.165030Z","shell.execute_reply.started":"2025-07-27T19:45:59.824424Z","shell.execute_reply":"2025-07-27T19:49:11.164100Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Collecting gymnasium>=1.2.0\n  Downloading gymnasium-1.2.0-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: imageio>=2.37.0 in /usr/local/lib/python3.11/dist-packages (2.37.0)\nCollecting lightning>=2.5.2\n  Downloading lightning-2.5.2-py3-none-any.whl.metadata (38 kB)\nCollecting matplotlib>=3.10.3\n  Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting minigrid>=3.0.0\n  Downloading minigrid-3.0.0-py3-none-any.whl.metadata (6.7 kB)\nRequirement already satisfied: pyyaml>=6.0.2 in /usr/local/lib/python3.11/dist-packages (6.0.2)\nCollecting seaborn>=0.13.2\n  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting tensorboard>=2.20.0\n  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting torch>=2.7.1\n  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.2.0) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.2.0) (3.1.1)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.2.0) (4.14.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.2.0) (0.0.4)\nRequirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio>=2.37.0) (11.2.1)\nRequirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.2) (2025.5.1)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.5.2) (0.14.3)\nRequirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.5.2) (25.0)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.5.2) (1.7.3)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.5.2) (4.67.1)\nRequirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning>=2.5.2) (2.5.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.10.3) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.10.3) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.10.3) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.10.3) (1.4.8)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.10.3) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.10.3) (2.9.0.post0)\nRequirement already satisfied: pygame>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from minigrid>=3.0.0) (2.6.1)\nRequirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn>=0.13.2) (2.2.3)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.20.0) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.20.0) (1.73.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.20.0) (3.8.2)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.20.0) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.20.0) (75.2.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.20.0) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.20.0) (3.1.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.1) (3.18.0)\nCollecting sympy>=1.13.3 (from torch>=2.7.1)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.1) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.1) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.7.1)\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.7.1)\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.7.1)\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.7.1)\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.6.4.1 (from torch>=2.7.1)\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.7.1)\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.7.1)\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.7.1)\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=2.7.1)\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.7.1)\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch>=2.7.1)\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.7.1)\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=2.7.1)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.7.1)\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.3.1 (from torch>=2.7.1)\n  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.2) (3.12.13)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium>=1.2.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium>=1.2.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium>=1.2.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium>=1.2.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium>=1.2.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.0->gymnasium>=1.2.0) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn>=0.13.2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn>=0.13.2) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.10.3) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.7.1) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.20.0) (3.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.2) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.2) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.2) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.2) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.2) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.2) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.2) (1.20.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->gymnasium>=1.2.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.0->gymnasium>=1.2.0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.0->gymnasium>=1.2.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.0->gymnasium>=1.2.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.0->gymnasium>=1.2.0) (2024.2.0)\nRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.5.2) (3.10)\nDownloading gymnasium-1.2.0-py3-none-any.whl (944 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m944.3/944.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading lightning-2.5.2-py3-none-any.whl (821 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.1/821.1 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading minigrid-3.0.0-py3-none-any.whl (136 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.7/136.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, matplotlib, gymnasium, tensorboard, seaborn, minigrid, lightning\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.2\n    Uninstalling matplotlib-3.7.2:\n      Successfully uninstalled matplotlib-3.7.2\n  Attempting uninstall: gymnasium\n    Found existing installation: gymnasium 0.29.0\n    Uninstalling gymnasium-0.29.0:\n      Successfully uninstalled gymnasium-0.29.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n  Attempting uninstall: seaborn\n    Found existing installation: seaborn 0.12.2\n    Uninstalling seaborn-0.12.2:\n      Successfully uninstalled seaborn-0.12.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nydata-profiling 4.16.1 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.3 which is incompatible.\nkaggle-environments 1.17.6 requires gymnasium==0.29.0, but you have gymnasium 1.2.0 which is incompatible.\nstable-baselines3 2.1.0 requires gymnasium<0.30,>=0.28.1, but you have gymnasium 1.2.0 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\ntorchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\ntensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.20.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gymnasium-1.2.0 lightning-2.5.2 matplotlib-3.10.3 minigrid-3.0.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 seaborn-0.13.2 sympy-1.14.0 tensorboard-2.20.0 torch-2.7.1 triton-3.3.1\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"### Base Agent","metadata":{}},{"cell_type":"code","source":"from abc import ABC,abstractmethod\nimport pytorch_lightning as pl\nfrom typing import Dict, Any\n\n\n\nclass BaseAgent(pl.LightningModule, ABC):\n    \"\"\"Base class for agents\"\"\"\n    \n    def __init__(self,config:Dict[str,Any]):\n        super().__init__()\n        self.config = config\n        self.save_hyperparameters(config)\n        \n    @abstractmethod\n    def act(self,obs:Dict[str,Any]):\n        \"\"\"select an action given the observation\"\"\"\n        pass\n    \n    @abstractmethod\n    def training_step(self,batch:Dict[str,Any],batch_idx:int):\n        \"\"\"training step for the agent\"\"\"\n        pass\n        \n    \n    def configure_optimizers(self):\n        \"\"\"configure the optimizer for the agent\"\"\"\n        raise NotImplementedError(\"Subclasses must implement the configure_optimizers method.\")\n    \n    \n    def save_checkpoint(self,path:str):\n        \"\"\"save the checkpoint for the agent\"\"\"\n        self.trainer.save_checkpoint(path)\n    \n    @classmethod\n    def load_checkpoint(cls,checkpoint_path:str,config=None):\n        \"\"\"load the checkpoint for the agent\"\"\"\n        if config is None :\n            return cls.load_from_checkpoint(checkpoint_path)\n        return cls.load_from_checkpoint(checkpoint_path,config=config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T19:30:58.384104Z","iopub.execute_input":"2025-07-27T19:30:58.384829Z","iopub.status.idle":"2025-07-27T19:30:58.390838Z","shell.execute_reply.started":"2025-07-27T19:30:58.384802Z","shell.execute_reply":"2025-07-27T19:30:58.390090Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Base Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\n\n\n\nclass BaseModel(nn.Module):\n    def __init__(self, ):\n        super().__init__()\n    \n    def forward(self, x):\n        raise NotImplementedError(\"Subclasses must implement the forward method.\")\n    \n    \n    def save(self, path: str):\n        torch.save(self.state_dict(), path)\n    \n    \n    def load(self, path: str):\n        self.load_state_dict(torch.load(path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T19:31:10.386383Z","iopub.execute_input":"2025-07-27T19:31:10.386660Z","iopub.status.idle":"2025-07-27T19:31:10.391391Z","shell.execute_reply.started":"2025-07-27T19:31:10.386637Z","shell.execute_reply":"2025-07-27T19:31:10.390595Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## DIAYN Agent","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.amp\nimport numpy as np\nfrom collections import deque, namedtuple\nfrom typing import Tuple, Dict, Any\n\n\n# Define transition tuple\nTransition = namedtuple('Transition', \n                       ('state', 'action', 'skill', 'next_state', 'done', 'reward'))\n\nclass MiniGridEncoder(BaseModel):\n    \"\"\"Encoder for the MiniGrid environment So that it can be used in the DIAYN agent\n    \n    Args:\n        input_shape (Tuple[int]): The shape of the input observation.\n        hidden_size (int): The size of the hidden layer.\n    \n    Returns:\n        torch.Tensor: The encoded observation.\n    \"\"\"\n    \n    def __init__(self, obs_shape: Tuple[int], feature_dim: int = 64, obs_type: str = \"rgb\"):\n        super().__init__()\n        self.obs_type = obs_type\n        self.obs_shape = obs_shape\n        \n        # Determine input channels based on observation type\n        self.in_channels = 3 if obs_type == \"rgb\" else 1\n        \n        # CNN architecture for processing observations\n        self.conv = nn.Sequential(\n            nn.Conv2d(self.in_channels, 16, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Flatten()\n        )\n        \n\n        with torch.no_grad():\n            # Create a dummy input with correct shape (N, C, H, W)\n            dummy = torch.zeros(1, self.in_channels, *obs_shape[:2])\n            conv_out = self.conv(dummy)\n            self.conv_output_dim = conv_out.shape[1]\n            \n\n        self.fc = nn.Linear(self.conv_output_dim, feature_dim)\n        self.feature_dim = feature_dim\n    \n    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n        \"\"\"Forward pass of the encoder\n        \n        Args:\n            obs (torch.Tensor): The input observation of shape (batch, H, W, C) or (H, W, C)\n            \n        Returns:\n            torch.Tensor: The encoded observation of shape (batch, hidden_dim)\n        \"\"\"\n        # Ensure we have a batch dimension\n        if len(obs.shape) == 3:  # (H, W, C) -> (1, H, W, C)\n            obs = obs.unsqueeze(0)\n            \n        # Convert to float and normalize if needed\n        if obs.dtype == torch.uint8:\n            obs = obs.float() / 255.0\n            \n        # Convert from NHWC to NCHW format expected by PyTorch\n        if obs.shape[-1] in [1, 3]:  # If channels are last\n            obs = obs.permute(0, 3, 1, 2)  # NHWC -> NCHW\n            \n        # Ensure we have the right number of channels\n        if self.obs_type == 'rgb' and obs.shape[1] != 3:\n            if obs.shape[1] == 1:  # If grayscale, repeat to 3 channels\n                obs = obs.repeat(1, 3, 1, 1)\n            else:\n                raise ValueError(f\"Expected 1 or 3 channels for RGB, got {obs.shape[1]} channels\")\n                \n\n        x = self.conv(obs)\n        return torch.relu(self.fc(x))\n    \n\n\n\n\nclass SkillDiscriminator(BaseModel):\n    \"\"\"\n    Skill discriminator for the DIAYN agent\n    \n    Args:\n        input_dim (int): The dimension of the input.\n        hidden_dim (int): The dimension of the hidden layer.\n    \n    Returns:\n        torch.Tensor: The skill discriminator output.\n    \"\"\"\n    \n    def __init__(self,state_dim,skill_dim,hidden_dim=64):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(state_dim,hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim,hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim,skill_dim)\n        )\n        \n    def forward(self,state:torch.Tensor):\n        return self.net(state)\n    \n    \n    def compute_reward(self,state,skill):\n        logits = self(state)\n        log_probs = F.log_softmax(logits,dim=-1)\n        return (log_probs * skill).sum(dim=-1) + np.log(skill.size(1))\n\n\n\nclass DIAYNAgent(BaseAgent):\n    \"\"\"DIAYN agent for the MiniGrid environment\"\"\"\n    def __init__(self,config:Dict[str,Any]):\n        super().__init__(config)\n        \n        #Environment parameters\n        self.obs_shape = config[\"agent\"][\"obs_shape\"]\n        self.action_dim = config[\"agent\"][\"action_dim\"]\n        self.skill_dim = config.get(\"skill_dim\",8)\n        self.obs_type = config.get(\"obs_type\",\"rgb\")\n        \n        # Training parameters\n        self.lr = float(config.get(\"lr\", 3e-4))\n        self.gamma = float(config.get(\"gamma\", 0.99))\n        self.entropy_coeff = float(config.get(\"entropy_coeff\", 0.01))\n        self.batch_size = int(config.get(\"batch_size\", 64))\n        self.replay_size = int(config.get(\"replay_size\", 10000))\n        self.entropy_coef = float(config.get(\"entropy_coef\", 0.01))\n        \n        #Models\n        self.encoder = MiniGridEncoder(self.obs_shape,\n                                       feature_dim = config.get(\"hidden_dim\",64),\n                                       obs_type = self.obs_type\n                                       ).to(self.device)\n        \n        #Policy Network \n        self.policy = nn.Sequential(\n            nn.Linear(self.encoder.feature_dim + self.skill_dim,64),\n            nn.ReLU(),\n            nn.Linear(64,64),\n            nn.ReLU(),\n            nn.Linear(64,self.action_dim)\n        ).to(self.device)\n        \n        #Discriminator Network\n        self.discriminator = SkillDiscriminator(\n            self.encoder.feature_dim,\n            self.skill_dim,\n            hidden_dim = config.get(\"hidden_dim\",64)\n        ).to(self.device)\n        \n        #Replay Buffer\n        self.replay_buffer = deque(maxlen=self.replay_size)\n        \n        #Metrics\n        self.episode_rewards = []\n        self.episode_lengths = []\n        \n    def forward(self,obs:torch.Tensor,skill:torch.Tensor,deterministic:bool=False) -> torch.Tensor:\n        \"\"\"\n        Forward pass of the agent\n        Args: \n            obs (torch.Tensor): The observation.\n            skill (torch.Tensor): The skill.\n        Returns:\n            torch.Tensor: The action.\n        \"\"\"\n        with torch.no_grad():\n            encoded_obs = self.encoder(obs) #return the state in latent space\n            x = torch.cat([encoded_obs,skill],dim=-1).to(self.device)\n            logits = self.policy(x).to(self.device)\n            if deterministic:\n                return torch.argmax(logits,dim=-1).to(self.device)\n            else:\n                probs = F.softmax(logits,dim=-1).to(self.device)\n                return torch.multinomial(probs,1).squeeze(-1).to(self.device)\n            \n    \n    def act(self,obs:torch.Tensor,skill:torch.Tensor=None,deterministic:bool=False) -> torch.Tensor:\n        \"\"\"Select an action given the observation and skill\"\"\"\n        if skill is None:\n            skill = self._sample_skill()\n        skill = torch.FloatTensor(skill).unsqueeze(0).to(self.device) if not isinstance(skill,torch.Tensor) else skill\n        obs = torch.FloatTensor(obs).unsqueeze(0).to(self.device) if not isinstance(obs,torch.Tensor) else obs\n        return self.forward(obs,skill,deterministic).cpu().numpy().item()\n    \n    def training_step(self, batch, batch_idx, optimizer_idx):\n        \"\"\"\n        Perform a single training step with mixed precision support.\n        \n        Args:\n            batch: Batch of transitions (if None, sample from replay buffer)\n            batch_idx: Batch index\n            optimizer_idx: Index of the optimizer (0: discriminator, 1: policy)\n            \n        Returns:\n            torch.Tensor: The computed loss\n        \"\"\"\n        # If batch is None, sample from replay buffer\n        if batch is None:\n            if len(self.replay_buffer) < self.batch_size:\n                return torch.tensor(0.0, device=self.device)\n            batch = self._sample_batch()\n            \n        states, actions, skills, next_states, dones, rewards = self._unpack_batch(batch)\n        \n        with torch.amp.autocast(device_type='cuda' if self.device.type == 'cuda' else 'cpu', \n                              enabled=self.device.type == 'cuda'):\n            # Encode states and next_states\n            with torch.no_grad():\n                states_enc = self.encoder(states)\n                next_states_enc = self.encoder(next_states)\n            \n            # Train Discriminator\n            if optimizer_idx == 0:\n                logits = self.discriminator(next_states_enc)\n                loss_d = F.cross_entropy(logits, skills.argmax(dim=-1))\n                self.log(\"train/loss_discriminator\", loss_d, prog_bar=True)\n                return loss_d\n                \n            # Compute Policy\n            if optimizer_idx == 1:\n                policy_input = torch.cat([states_enc, skills], dim=-1)\n                logits = self.policy(policy_input)\n                \n                probs = F.softmax(logits, dim=-1)\n                log_probs = F.log_softmax(logits, dim=-1)\n                entropy = -(probs * log_probs).sum(dim=-1)\n                \n                with torch.no_grad():\n                    intrinsic_reward = self.discriminator.compute_reward(next_states_enc, skills)\n                    \n                # Compute policy gradient loss\n                policy_loss = -(log_probs.gather(1, actions.unsqueeze(1)) * intrinsic_reward.detach()).mean()\n                entropy_loss = -self.entropy_coef * entropy.mean()\n                \n                total_loss = policy_loss + entropy_loss\n                \n                # Log metrics\n                self.log(\"train/loss_policy\", policy_loss, prog_bar=True)\n                self.log(\"train/entropy\", entropy.mean(), prog_bar=True)\n                self.log(\"train/total_loss\", total_loss)\n                self.log(\"train/avg_intrinsic_reward\", intrinsic_reward.mean())\n                \n                return total_loss\n            \n    def configure_optimizers(self):\n        \"\"\"Configure optimizers for discriminator and policy with weight decay.\"\"\"\n        # Use AdamW with weight decay\n        opt_d = torch.optim.AdamW(\n            self.discriminator.parameters(), \n            lr=self.lr,\n            weight_decay=1e-5,\n            eps=1e-5\n        )\n        opt_p = torch.optim.AdamW(\n            list(self.encoder.parameters()) + list(self.policy.parameters()),\n            lr=self.lr,\n            weight_decay=1e-5,\n            eps=1e-5\n        )\n        \n        # Learning rate scheduling\n        scheduler_d = torch.optim.lr_scheduler.CosineAnnealingLR(opt_d, T_max=1000)\n        scheduler_p = torch.optim.lr_scheduler.CosineAnnealingLR(opt_p, T_max=1000)\n        \n        return [opt_d, opt_p], [scheduler_d, scheduler_p]   \n        \n    def _unpack_batch(self, batch):\n        \"\"\"Unpack a batch of transitions from the replay buffer.\n        \n        Args:\n            batch: Batch of transitions. Can be:\n                - List of transitions (state, action, skill, next_state, done, reward)\n                - Tuple of (states, actions, skills, next_states, dones, rewards)\n                \n        Returns:\n            tuple: (states, actions, skills, next_states, dones, rewards) as torch tensors\n        \"\"\"\n        # Handle case where batch is already a tuple of tensors\n        if isinstance(batch, (list, tuple)) and len(batch) == 6 and all(torch.is_tensor(x) for x in batch):\n            return batch\n            \n        # Handle case where batch is a list of transitions\n        if isinstance(batch, list) and len(batch) > 0 and isinstance(batch[0], (list, tuple)):\n            # Transpose the batch: from list of transitions to list of fields\n            states, actions, skills, next_states, dones, rewards = zip(*batch)\n        else:\n            # Assume batch is already in the correct format\n            states, actions, skills, next_states, dones, rewards = batch\n        \n        # Convert to numpy arrays if they aren't already\n        states = np.array(states) if not isinstance(states, np.ndarray) else states\n        next_states = np.array(next_states) if not isinstance(next_states, np.ndarray) else next_states\n        skills = np.array(skills) if not isinstance(skills, np.ndarray) else skills\n        \n        # Convert to tensors and move to device\n        states = torch.as_tensor(states, dtype=torch.float32, device=self.device)\n        actions = torch.as_tensor(actions, dtype=torch.long, device=self.device)\n        skills = torch.as_tensor(skills, dtype=torch.float32, device=self.device)\n        next_states = torch.as_tensor(next_states, dtype=torch.float32, device=self.device)\n        dones = torch.as_tensor(dones, dtype=torch.float32, device=self.device)\n        rewards = torch.as_tensor(rewards, dtype=torch.float32, device=self.device)\n        \n        # Ensure correct shapes\n        if len(states.shape) == 3:  # (B, H, W) -> (B, 1, H, W)\n            states = states.unsqueeze(1)\n        if len(next_states.shape) == 3:\n            next_states = next_states.unsqueeze(1)\n            \n        return states, actions, skills, next_states, dones, rewards\n        \n    def _sample_batch(self):\n        \"\"\"Sample a batch from replay buffer.\"\"\"\n        if len(self.replay_buffer) < self.batch_size:\n            batch_size = len(self.replay_buffer)\n        else:\n            batch_size = self.batch_size\n            \n        # Sample random indices\n        indices = np.random.choice(len(self.replay_buffer), size=batch_size, replace=False)\n        transitions = [self.replay_buffer[i] for i in indices]\n        batch = Transition(*zip(*transitions))\n        \n        return (\n            torch.stack(batch.state).to(self.device),\n            torch.cat(batch.action).to(self.device),\n            torch.stack(batch.skill).to(self.device),\n            torch.stack(batch.next_state).to(self.device),\n            torch.stack(batch.done).to(self.device),\n            torch.stack(batch.reward).to(self.device)\n        )\n    \n    \n    def _sample_skill(self):\n        \"\"\"Sample a random one-hot skill vector\"\"\"\n        skill = np.zeros(self.skill_dim)\n        skill[np.random.randint(self.skill_dim)] = 1\n        return skill\n\n    \n    def add_to_replay(self,state,action,skill,next_state,done,reward):\n        \n        \"\"\"Add transition to replay buffer.\"\"\"\n        self.replay_buffer.append(Transition(\n            torch.FloatTensor(state).to(self.device),\n            torch.LongTensor([action]).to(self.device),\n            torch.FloatTensor(skill).to(self.device),\n            torch.FloatTensor(next_state).to(self.device),\n            torch.FloatTensor([done]).to(self.device),\n            torch.FloatTensor([reward]).to(self.device)\n        ))","metadata":{"_uuid":"dc47ed0e-c3be-4110-9b27-b6785df12089","_cell_guid":"ec778f9f-36be-4a40-ab30-f24f17d91a8b","trusted":true,"execution":{"iopub.status.busy":"2025-07-27T19:31:52.168199Z","iopub.execute_input":"2025-07-27T19:31:52.168489Z","iopub.status.idle":"2025-07-27T19:31:52.199611Z","shell.execute_reply.started":"2025-07-27T19:31:52.168468Z","shell.execute_reply":"2025-07-27T19:31:52.198940Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Configs","metadata":{}},{"cell_type":"code","source":"with open(\"diayn.yaml\",\"w\") as f :\n    f.write(\"\"\"\n# configs/diayn.yaml\n# DIAYN (Diversity is All You Need) Configuration\n# Reference: https://arxiv.org/abs/1802.06070\n\n# ===== Environment Configuration =====\nenv_id: \"MiniGrid-Empty-8x8-v0\"  # MiniGrid environment ID\nobs_type: \"rgb\"  # Observation type: \"rgb\" (3-channel) or \"grid\" (single-channel)\n\n# Available MiniGrid environments (uncomment to use):\n# - \"MiniGrid-Empty-5x5-v0\"\n# - \"MiniGrid-Empty-8x8-v0\"\n# - \"MiniGrid-Empty-16x16-v0\"\n# - \"MiniGrid-DoorKey-5x5-v0\"\n# - \"MiniGrid-DoorKey-8x8-v0\"\n# - \"MiniGrid-FourRooms-v0\"\n\n# ===== Agent Configuration =====\nagent:\n  # Observation and action spaces (will be auto-filled)\n  obs_shape: [7, 7, 3]  # [height, width, channels] - will be overridden\n  action_dim: 7  # MiniGrid action space size - will be overridden\n  \n  # Skill configuration\n  skill_dim: 8  # Number of discrete skills to learn\n  \n  # Network architecture\n  hidden_dim: 256  # Hidden layer size for all networks\n  \n  # Training hyperparameters\n  lr: 3e-4  # Learning rate\n  gamma: 0.99  # Discount factor\n  entropy_coef: 0.1  # Entropy coefficient for policy gradient\n  \n  # Replay buffer\n  batch_size: 512  # Batch size for training\n  replay_size: 50000  # Maximum replay buffer size\n  \n  # Intrinsic reward scaling\n  intrinsic_reward_scale: 1.0  # Scale factor for intrinsic rewards\n  \n  # Device configuration\n  device: \"auto\"  # \"auto\", \"cpu\", or \"cuda\"\n\n# ===== Training Configuration =====\ntraining:\n  # Training procedure\n  max_episodes: 100000 # Maximum number of training episodes\n  max_steps_per_episode: 200  # Maximum steps per episode\n  \n  # Logging and evaluation\n  log_interval: 100  # Log metrics every N episodes\n  eval_interval: 500  # Evaluate every N episodes\n  eval_episodes: 50  # Number of evaluation episodes\n  \n  # Checkpointing\n  save_interval: 10000  # Save model every N episodes\n  \n  # Early stopping (optional)\n  early_stop_reward: None  # Stop training if average reward exceeds this value\n  patience: 100  # Number of episodes to wait before early stopping\n\n# ===== Logging Configuration =====\nlogging:\n  log_dir: \"logs\"  # Base directory for logs\n  project_name: \"skill-discovery\"  # Project name for experiment tracking\n  use_tensorboard: true  # Enable TensorBoard logging\n  save_video: false  # Save video of agent's performance\n  video_interval: 1000  # Save video every N episodes\n\n# ===== Notes =====\n# 1. obs_shape and action_dim will be automatically set based on the environment\n# 2. For best results, adjust batch_size and replay_size based on available memory\n# 3. Increase skill_dim for more diverse behaviors, but training will be slower\n# 4. Monitor training progress using TensorBoard: `tensorboard --logdir=logs`\n    \"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T19:41:14.883377Z","iopub.execute_input":"2025-07-27T19:41:14.884078Z","iopub.status.idle":"2025-07-27T19:41:14.889261Z","shell.execute_reply.started":"2025-07-27T19:41:14.884052Z","shell.execute_reply":"2025-07-27T19:41:14.888382Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"### MinitGrid init","metadata":{}},{"cell_type":"code","source":"\"\"\"Register MiniGrid environments with Gymnasium.\"\"\"\nfrom gymnasium.envs.registration import register\n\n# Register all available MiniGrid environments\nregister(\n    id=\"MiniGrid-Empty-5x5-v0\",\n    entry_point=\"minigrid.envs:EmptyEnv\",\n    kwargs={\"size\": 5}\n)\n\nregister(\n    id=\"MiniGrid-Empty-8x8-v0\",\n    entry_point=\"minigrid.envs:EmptyEnv\",\n    kwargs={\"size\": 8}\n)\n\nregister(\n    id=\"MiniGrid-Empty-16x16-v0\",\n    entry_point=\"minigrid.envs:EmptyEnv\",\n    kwargs={\"size\": 16}\n)\n\n# You can add more environments as needed\nregister(\n    id=\"MiniGrid-DoorKey-5x5-v0\",\n    entry_point=\"minigrid.envs:DoorKeyEnv\",\n    kwargs={\"size\": 5}\n)\n\nregister(\n    id=\"MiniGrid-DoorKey-8x8-v0\",\n    entry_point=\"minigrid.envs:DoorKeyEnv\",\n    kwargs={\"size\": 8}\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T19:43:26.938455Z","iopub.execute_input":"2025-07-27T19:43:26.938725Z","iopub.status.idle":"2025-07-27T19:43:26.944261Z","shell.execute_reply.started":"2025-07-27T19:43:26.938705Z","shell.execute_reply":"2025-07-27T19:43:26.943538Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import gymnasium as gym\nimport numpy as np\nfrom gymnasium import spaces\n\n\n\nclass MiniGridWrapper(gym.Wrapper):\n    \"\"\"Wrapper for the MiniGrid environment\"\"\"\n    def __init__(self,env,skill_dim=8,obs_type=\"rgb\"):\n        super().__init__(env)\n        self.skill_dim = skill_dim\n        self.obs_type = obs_type\n        \n        if obs_type == \"rgb\":\n            self.obs_shape = (7,7,3)\n        else: #obs_type = grid\n            self.obs_shape = (7,7)\n        \n        self.observation_space = spaces.Dict({\n            \"observation\": spaces.Box(\n                low=0,high=255,\n                shape=self.obs_shape,\n                dtype=np.uint8\n            ),\n            \"skill\": spaces.Box(\n                low=-1.0,high=1.0,\n                shape=(skill_dim,),\n                dtype=np.float32\n            )\n        })\n    \n    def reset(self,**kwargs):\n        obs,info = super().reset(**kwargs)\n        return self._process_obs(obs),info\n    \n    def step(self,action):\n        obs,reward,terminated,truncated,info = self.env.step(action)\n        return self._process_obs(obs),reward,terminated,truncated,info\n    \n    def _process_obs(self,obs):\n        \"\"\"\n        Process the observation to match the observation space\n        \"\"\"\n        \n        if self.obs_type == \"rgb\":\n            obs_array = obs[\"image\"][...,:3]\n        else:\n            obs_array = obs[\"image\"][...,0]\n        \n        skill = np.random.uniform(-1,1,size=(self.skill_dim,))\n        \n        return {\n            \"observation\":obs_array,\n            \"skill\":skill\n        }\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T19:43:39.034445Z","iopub.execute_input":"2025-07-27T19:43:39.034970Z","iopub.status.idle":"2025-07-27T19:43:39.042192Z","shell.execute_reply.started":"2025-07-27T19:43:39.034947Z","shell.execute_reply":"2025-07-27T19:43:39.041404Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"### Train","metadata":{}},{"cell_type":"code","source":"import os\nimport yaml\nimport argparse\nimport gymnasium as gym\nimport numpy as np\nimport torch\nimport torch.optim as optim\nimport torch.amp\nfrom pathlib import Path\nfrom datetime import datetime\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n\n\ndef parse_args():\n    import sys\n    sys.argv = ['']\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--config\", type=str, default=\"/kaggle/working/diayn.yaml\")\n    parser.add_argument(\"--log_dir\", type=str, default=\"logs\")\n    return parser.parse_args()\n\ndef load_config(config_path):\n    with open(config_path, \"r\") as f:\n        return yaml.safe_load(f)\n\ndef collect_rollout(env, agent, max_steps=1000):\n    \"\"\"Collect a single rollout from the environment with optimized data transfer.\"\"\"\n    obs, _ = env.reset()\n    skill = agent._sample_skill()\n    episode_reward = 0\n    episode_length = 0\n    \n    # Convert initial observation to tensor\n    obs_array = np.asarray(obs[\"observation\"], dtype=np.float32)\n    \n    for _ in range(max_steps):\n        # Convert to tensor and move to device\n        obs_tensor = torch.from_numpy(obs_array).unsqueeze(0).to(agent.device)\n        skill_tensor = torch.FloatTensor(skill).unsqueeze(0).to(agent.device)\n        \n        # Ensure tensors are contiguous\n        obs_tensor = obs_tensor.contiguous()\n        skill_tensor = skill_tensor.contiguous()\n        \n        # Get action from agent\n        with torch.no_grad(), torch.amp.autocast(device_type='cuda' if agent.device.type == 'cuda' else 'cpu', enabled=agent.device.type == 'cuda'):\n            action = agent.act(obs_tensor, skill_tensor, deterministic=False)\n        \n        # Step environment\n        next_obs, reward, done, _, _ = env.step(action.item() if torch.is_tensor(action) else action)\n        \n        # Convert next observation to numpy\n        next_obs_array = np.asarray(next_obs[\"observation\"], dtype=np.float32)\n        \n        # Store transition\n        agent.add_to_replay(\n            obs_array,  # Use numpy array\n            action.item() if torch.is_tensor(action) else action,\n            skill,\n            next_obs_array,  # Use numpy array\n            done,\n            reward\n        )\n        \n        # Update state\n        obs_array = next_obs_array\n        obs = next_obs\n        episode_reward += reward\n        episode_length += 1\n        \n        if done:\n            break\n            \n        # Clear CUDA cache periodically\n        if episode_length % 100 == 0 and torch.cuda.is_available():\n            torch.cuda.empty_cache()\n            \n    return episode_reward, episode_length\n\ndef train():\n    args = parse_args()\n    config = load_config(args.config)\n    \n    # Set up device and mixed precision\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n    \n    # Initialize mixed precision training\n    scaler = torch.amp.GradScaler(enabled=device.type == 'cuda')\n    \n    # Create environment\n    env = gym.make(config[\"env_id\"], render_mode=\"rgb_array\")\n    env = MiniGridWrapper(\n        env, \n        skill_dim=config[\"agent\"][\"skill_dim\"],\n        obs_type=config[\"obs_type\"]\n    )\n    \n    # Update obs_shape in config\n    config[\"agent\"][\"obs_shape\"] = env.observation_space[\"observation\"].shape\n    config[\"agent\"][\"action_dim\"] = env.action_space.n\n    \n    # Initialize agent with config\n    agent = DIAYNAgent(config).to(device)\n    \n    agent.train()\n    \n    # Enable optimizations if using CUDA\n    if device.type == 'cuda':\n        torch.backends.cudnn.benchmark = True\n        torch.backends.cuda.matmul.allow_tf32 = True\n        torch.backends.cudnn.allow_tf32 = True\n        \n        # Print GPU info\n        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n        print(f\"CUDA available: {torch.cuda.is_available()}\")\n        print(f\"CUDA version: {torch.version.cuda}\")\n        print(f\"PyTorch version: {torch.__version__}\")\n\n\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    log_dir = os.path.join(args.log_dir, f\"diayn_{timestamp}\")\n    os.makedirs(log_dir, exist_ok=True)\n    \n    logger = TensorBoardLogger(\n        save_dir=args.log_dir,\n        name=\"diayn\",\n        version=timestamp\n    )\n        \n\n    checkpoint_dir = os.path.join(log_dir, \"checkpoints\")\n    os.makedirs(checkpoint_dir, exist_ok=True)\n    \n    checkpoint_callback = ModelCheckpoint(\n        dirpath=checkpoint_dir,\n        filename=\"diayn-{epoch:03d}\",\n        save_top_k=3,\n        monitor=\"train/avg_reward\",\n        mode=\"max\",\n    )\n    \n    # Training parameters from config\n    num_episodes = config.get(\"training\", {}).get(\"num_episodes\", 1000)\n    max_steps = config.get(\"training\", {}).get(\"max_steps\", 1000)\n    log_interval = config.get(\"training\", {}).get(\"log_interval\", 10)\n    eval_interval = config.get(\"training\", {}).get(\"eval_interval\", 50)\n    save_interval = config.get(\"training\", {}).get(\"save_interval\", 100)\n    checkpoint_dir = Path(config.get(\"training\", {}).get(\"checkpoint_dir\", \"checkpoints\"))\n    \n    # Create progress bar\n    pbar = tqdm(range(1, num_episodes + 1), desc=\"Training\", unit=\"episode\")\n    \n    # Initialize optimizers\n    optimizers = agent.configure_optimizers()\n    if isinstance(optimizers, (list, tuple)) and len(optimizers) > 0:\n        if isinstance(optimizers[0], (list, tuple)):\n            # Handle case where optimizers is a list of optimizers and schedulers\n            optimizers = optimizers[0]\n    \n    # Unpack optimizers if we have multiple\n    if isinstance(optimizers, (list, tuple)) and len(optimizers) >= 2:\n        optimizer_d, optimizer_p = optimizers[0], optimizers[1]\n    else:\n        # Fallback to single optimizer if needed\n        optimizer_d = optimizers[0] if isinstance(optimizers, (list, tuple)) else optimizers\n        optimizer_p = optimizer_d\n    \n    episode_rewards = []\n    episode_lengths = []\n    total_steps = 0\n    best_reward = -float('inf')\n    \n    for episode in pbar:\n        try:\n            # Set models to train mode\n            agent.train()\n            \n            # Collect rollout\n            episode_reward, episode_length = collect_rollout(env, agent, max_steps)\n            \n            # Store metrics\n            episode_rewards.append(episode_reward)\n            episode_lengths.append(episode_length)\n            total_steps += episode_length\n            \n            # Calculate running averages\n            avg_reward = np.mean(episode_rewards[-100:]) if episode_rewards else 0\n            avg_length = np.mean(episode_lengths[-100:]) if episode_lengths else 0\n            \n            # Update progress bar\n            pbar.set_postfix({\n                'reward': f'{episode_reward:.2f}',\n                'avg_reward': f'{avg_reward:.2f}',\n                'length': episode_length,\n                'steps': total_steps\n            })\n            \n            # Log metrics\n            if logger is not None:\n                logger.experiment.add_scalar(\"train/episode_reward\", episode_reward, episode)\n                logger.experiment.add_scalar(\"train/episode_length\", episode_length, episode)\n                logger.experiment.add_scalar(\"train/avg_reward\", avg_reward, episode)\n                logger.experiment.add_scalar(\"train/avg_length\", avg_length, episode)\n                logger.experiment.add_scalar(\"train/total_steps\", total_steps, episode)\n            \n            # Save best model\n            if episode_reward > best_reward:\n                best_reward = episode_reward\n                if logger is not None and hasattr(logger, 'save_checkpoint'):\n                    checkpoint = {\n                        'episode': episode,\n                        'model_state_dict': agent.state_dict(),\n                        'reward': episode_reward,\n                        'optimizer_state_dict': [opt.state_dict() for opt in optimizers] if isinstance(optimizers, list) else optimizers.state_dict(),\n                    }\n                    logger.save_checkpoint(checkpoint, is_best=True)\n            \n            # Save model at intervals\n            if episode % save_interval == 0 and logger is not None and hasattr(logger, 'save_checkpoint'):\n                checkpoint = {\n                    'episode': episode,\n                    'model_state_dict': agent.state_dict(),\n                    'reward': episode_reward,\n                    'optimizer_state_dict': [opt.state_dict() for opt in optimizers] if isinstance(optimizers, list) else optimizers.state_dict(),\n                }\n                logger.save_checkpoint(checkpoint, is_best=False, filename=f'checkpoint_ep{episode}.pt')\n            \n            # Clear CUDA cache periodically\n            if episode % 10 == 0 and torch.cuda.is_available():\n                torch.cuda.empty_cache()\n                \n        except Exception as e:\n            print(f\"Error during episode {episode}: {str(e)}\")\n            import traceback\n            traceback.print_exc()\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n            continue\n        \n        # Perform training step\n        if len(agent.replay_buffer) >= agent.batch_size:\n            try:\n                # Train discriminator\n                optimizer_d.zero_grad()\n                with torch.amp.autocast(device_type='cuda' if agent.device.type == 'cuda' else 'cpu', enabled=agent.device.type == 'cuda'):\n                    loss_d = agent.training_step(None, episode, optimizer_idx=0)\n                scaler.scale(loss_d).backward()\n                scaler.step(optimizer_d)\n                scaler.update()\n                \n                # Train policy\n                optimizer_p.zero_grad()\n                with torch.amp.autocast(device_type='cuda' if agent.device.type == 'cuda' else 'cpu', enabled=agent.device.type == 'cuda'):\n                    loss_p = agent.training_step(None, episode, optimizer_idx=1)\n                scaler.scale(loss_p).backward()\n                scaler.step(optimizer_p)\n                \n                # Update scaler for next iteration\n                scaler.update()\n                \n                # Log training metrics\n                if logger is not None:\n                    logger.experiment.add_scalar(\"train/loss_discriminator\", loss_d.item(), episode)\n                    logger.experiment.add_scalar(\"train/loss_policy\", loss_p.item(), episode)\n                    \n            except RuntimeError as e:\n                print(f\"Error during training step: {str(e)}\")\n                if torch.cuda.is_available():\n                    torch.cuda.empty_cache()\n                    torch.cuda.synchronize()  # Wait for all kernels to finish\n            \n            if logger:\n                logger.experiment.add_scalar(\"train/loss_discriminator\", loss_d.item(), episode)\n                logger.experiment.add_scalar(\"train/loss_policy\", loss_p.item(), episode)\n        \n        # Perform evaluation\n        if (episode + 1) % eval_interval == 0:\n            agent.eval()\n            eval_rewards = []\n            with torch.no_grad():\n                for _ in range(5):\n                    eval_reward, _ = collect_rollout(env, agent)\n                    eval_rewards.append(eval_reward)\n            \n            avg_eval_reward = np.mean(eval_rewards)\n            if logger:\n                logger.experiment.add_scalar(\"eval/avg_reward\", avg_eval_reward, episode)\n            \n            agent.train()\n        \n\n        if (episode + 1) % save_interval == 0 or episode == num_episodes - 1:\n            os.makedirs(checkpoint_dir, exist_ok=True)\n            checkpoint_path = os.path.join(checkpoint_dir, f\"diayn_episode_{episode+1}.ckpt\")\n            torch.save({\n                'episode': episode,\n                'model_state_dict': agent.state_dict(),\n                'optimizer_d_state_dict': optimizer_d.state_dict(),\n                'optimizer_p_state_dict': optimizer_p.state_dict(),\n                'episode_rewards': episode_rewards,\n                'episode_lengths': episode_lengths,\n                'config': config\n            }, checkpoint_path)\n    \n\n    final_model_path = os.path.join(checkpoint_dir, \"diayn_final.pt\")\n    torch.save({\n        'model_state_dict': agent.state_dict(),\n        'config': config\n    }, final_model_path)\n    print(f\"\\nTraining complete! Final model saved to {final_model_path}\")\n    \n\n    metrics = {\n        'episode_rewards': episode_rewards,\n        'episode_lengths': episode_lengths,\n        'config': config\n    }\n    \n    metrics_path = os.path.join(log_dir, 'training_metrics.pt')\n    torch.save(metrics, metrics_path)\n    print(f\"Training metrics saved to {metrics_path}\")\n    \n    return agent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T19:41:44.428642Z","iopub.execute_input":"2025-07-27T19:41:44.428972Z","iopub.status.idle":"2025-07-27T19:41:44.461297Z","shell.execute_reply.started":"2025-07-27T19:41:44.428949Z","shell.execute_reply":"2025-07-27T19:41:44.460546Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-27T19:49:23.801908Z","iopub.execute_input":"2025-07-27T19:49:23.802210Z","iopub.status.idle":"2025-07-27T20:05:37.146516Z","shell.execute_reply.started":"2025-07-27T19:49:23.802184Z","shell.execute_reply":"2025-07-27T20:05:37.145946Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment MiniGrid-DoorKey-5x5-v0 already in registry.\u001b[0m\n  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment MiniGrid-DoorKey-8x8-v0 already in registry.\u001b[0m\n  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment MiniGrid-Empty-5x5-v0 already in registry.\u001b[0m\n  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment MiniGrid-Empty-8x8-v0 already in registry.\u001b[0m\n  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment MiniGrid-Empty-16x16-v0 already in registry.\u001b[0m\n  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","output_type":"stream"},{"name":"stdout","text":"GPU: Tesla P100-PCIE-16GB\nCUDA available: True\nCUDA version: 12.4\nPyTorch version: 2.6.0+cu124\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/1000 [00:00<?, ?episode/s, reward=0.54, avg_reward=0.54, length=132, steps=132]/usr/local/lib/python3.11/dist-packages/pytorch_lightning/core/module.py:441: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\nTraining: 100%|██████████| 1000/1000 [16:12<00:00,  1.03episode/s, reward=-0.36, avg_reward=-0.43, length=387, steps=582012]","output_type":"stream"},{"name":"stdout","text":"\nTraining complete! Final model saved to checkpoints/diayn_final.pt\nTraining metrics saved to logs/diayn_20250727_194924/training_metrics.pt\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"DIAYNAgent(\n  (encoder): MiniGridEncoder(\n    (conv): Sequential(\n      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU()\n      (4): Flatten(start_dim=1, end_dim=-1)\n    )\n    (fc): Linear(in_features=1568, out_features=64, bias=True)\n  )\n  (policy): Sequential(\n    (0): Linear(in_features=72, out_features=64, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=64, out_features=7, bias=True)\n  )\n  (discriminator): SkillDiscriminator(\n    (net): Sequential(\n      (0): Linear(in_features=64, out_features=64, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=64, out_features=8, bias=True)\n    )\n  )\n)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}